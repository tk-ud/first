MFC構造に基づく APIアタッチメント群ドキュメント

目的

本ドキュメントは、MFC構造エンジンに取り付け可能な「APIアタッチメント群」を整理し、特にsin波などのリアクティブ可視化系、センサ連携系、学習系のアプローチを含めて構造化することを目的とする。


---

構造概要

MFC構造では、以下の構成によってAPIアタッチメントが機能単位で増設される：

phase_map.yaml：処理の定義とフェーズ化

functionScore：各関数の実行スコア記録

emotion_log：構造またはユーザー反応の感情的記録

trigger_map.yaml：再構成/通知トリガー

WebSocket可視化：波形/構造的フィードバック出力



---

1. リアクティブ波形API（sin波）

エンドポイント例

GET /api/attachment/sin：WebSocket接続開始

POST /api/attachment/zscore：外部入力による振幅変調


仕様

周期：2π（~6.28）

fps：最大60（推奨：30）

変調：zスコア or emotion_logの影響値



---

2. 音声周波数アタッチメント

エンドポイント例

POST /api/audio/frame：1フレームごとのFFTデータ送信

GET /api/audio/heatmap：周波数マップを返却


利用目的

emotion_log生成（高音=テンション、低音=落ち着き）

functionScoreへの入力特徴量化



---

3. マルチセンサ統合アタッチメント

対象センサ

マイク（音量/周波数）

加速度・ジャイロ

環境光・近接センサ

カメラRGB（zScore）


データフォーマット

{
  "timestamp": "...",
  "mic": {"fft_peak": 480, "volume": 0.72},
  "gyro": {"x": 0.02, "y": -0.03, "z": 0.00},
  "visual_zscore": [0.12, -0.55, 0.33, ...]
}


---

備考

本仕様は“天才的思いつき”から生まれたが、構造知性として整合性を持つ形でAPI化可能

サーバーは軽量でも実現可能（5fps制限、分割セグメント処理）

UIはFlutterまたはReactでWebSocket波形対応



---

次ステップ

phase_map.yamlテンプレートとのリンク定義

emotion_log, functionScoreとのマッピング仕様明文化

実装プロトタイプへの展開



